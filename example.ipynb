{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbbc0193",
   "metadata": {},
   "source": [
    "# Simple Tar Dataset - examples\n",
    "\n",
    "This notebook will go through a few common use cases. All the needed Tar files are very minimal and included with the library.\n",
    "\n",
    "\n",
    "### Just load the images\n",
    "\n",
    "The default `TarDataset` simply loads all PNG, JPG and JPEG images from a Tar file, and allows you to iterate them.\n",
    "\n",
    "Images are returned as `Tensor`. Here some RGB values are printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf9947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image #0, color: tensor([0., 0., 1.])\n",
      "Image #1, color: tensor([0., 1., 0.])\n",
      "Image #2, color: tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from tardataset import TarDataset\n",
    "\n",
    "dataset = TarDataset('example-data/colors.tar')\n",
    "\n",
    "for (idx, image) in enumerate(dataset):\n",
    "    print(f\"Image #{idx}, color: {image[:,0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2d85ad",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Folders as class labels (like torchvision's ImageFolder)\n",
    "\n",
    "Similarly to [`ImageFolder`](https://pytorch.org/vision/stable/datasets.html#imagefolder), `TarImageFolder` assumes that each top-level folder contains all samples of a different class.\n",
    "\n",
    "In this example, the Tar archive has this structure:\n",
    "- `red/a.png`\n",
    "- `green/b.png`\n",
    "- `blue/c.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47601d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image #0, label: 0 (blue), color: tensor([0., 0., 1.])\n",
      "Image #1, label: 1 (green), color: tensor([0., 1., 0.])\n",
      "Image #2, label: 2 (red), color: tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from tarimagefolder import TarImageFolder\n",
    "\n",
    "dataset = TarImageFolder('example-data/colors.tar')\n",
    "\n",
    "for (idx, (image, label)) in enumerate(dataset):\n",
    "  print(f\"Image #{idx}, label: {label} \"\n",
    "        f\"({dataset.idx_to_class[label]}), color: {image[:,0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9250485",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Use a DataLoader (multiple processes) and return a mini-batch\n",
    "\n",
    "Using a `DataLoader` is the same as with a standard `Dataset`. The library supports various multiprocessing configurations without extra code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fab70ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of image batch: torch.Size([3, 3, 8, 8])\n",
      "Labels in batch: tensor([2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if __name__ == '__main__':  # needed for dataloaders\n",
    "  dataset = TarImageFolder('example-data/colors.tar')\n",
    "  loader = DataLoader(dataset, batch_size=3, num_workers=2, shuffle=True)\n",
    "\n",
    "  for (image, label) in loader:\n",
    "    print(f\"Dimensions of image batch: {image.shape}\")\n",
    "    print(f\"Labels in batch: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02c822",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Load videos as stacks of frames (custom Tar structures)\n",
    "\n",
    "To have more control over how files in the Tar archive are related to iterated samples, you can subclass `TarDataset`.\n",
    "\n",
    "Here we consider each folder starting with `'vid'` as a sample, load 3 sequentially-named frames from it, and return the concatenated frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3543c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video #0, stack of frames with dims: torch.Size([3, 3, 8, 8])\n",
      "Video #1, stack of frames with dims: torch.Size([3, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "class VideoDataset(TarDataset):\n",
    "  \"\"\"Example video dataset, each folder has the frames of a video\"\"\"\n",
    "  def __init__(self, archive):\n",
    "    super().__init__(archive=archive,\n",
    "      is_valid_file=lambda m: m.isdir() and m.name.startswith('vid'))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \"\"\"Load and return a stack of 3 frames from this folder\"\"\"\n",
    "    folder = self.samples[index]\n",
    "    images = [self.get_image(f\"{folder}/{frame:02}.png\")\n",
    "      for frame in range(3)]\n",
    "    return torch.stack(images)\n",
    "\n",
    "\n",
    "dataset = VideoDataset('example-data/videos.tar')\n",
    "\n",
    "for (idx, video) in enumerate(dataset):\n",
    "  print(f\"Video #{idx}, stack of frames with dims: {video.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c455e48",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Load non-image files, such as pickled Python objects\n",
    "\n",
    "You can choose the loaded file types with `extensions` (or the more advanced `is_valid_file`, as above).\n",
    "\n",
    "You can also use `get_file` to load arbitrary files as data streams, completely in-memory (without writing them to disk). You can plug this in to Pickle or JSON modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3ea097c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample #0, object: {'id': 0, 'content': 'one sample'}\n",
      "Sample #1, object: {'id': 1, 'content': 'another sample'}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "class PickleDataset(TarDataset):\n",
    "  \"\"\"Example non-image dataset\"\"\"\n",
    "  def __init__(self, archive):\n",
    "    super().__init__(archive=archive, extensions=('.pickle'))\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \"\"\"Return a pickled Python object\"\"\"\n",
    "    filename = self.samples[index]\n",
    "    return pickle.load(self.get_file(filename))\n",
    "\n",
    "\n",
    "dataset = PickleDataset('example-data/objects.tar')\n",
    "\n",
    "for (idx, obj) in enumerate(dataset):\n",
    "  print(f\"Sample #{idx}, object: {obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3cde7f5",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Load custom meta-data files (e.g. ground truth information)\n",
    "\n",
    "Often datasets come with various pieces of information in different files. You can easily read a text file from the Tar archive into a string with `get_text_file`, either at initialisation or during iteration. For more general binary files, use `get_file` as above.\n",
    "\n",
    "In this example we read a text file from the archive, which contains the file name of each image and its label `'red'` or `'not-red'` (one per line). When the dataset is iterated, `__getitem__` then returns the image and this custom label as a boolean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc95f93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image #0, redness: False, color: tensor([0., 0., 1.])\n",
      "Image #1, redness: False, color: tensor([0., 1., 0.])\n",
      "Image #2, redness: True, color: tensor([1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "class RedDataset(TarDataset):\n",
    "  \"\"\"Example dataset, which loads from a text file a binary label of\n",
    "  whether each image is red or not.\"\"\"\n",
    "  def __init__(self, archive):\n",
    "    super().__init__(archive=archive)\n",
    "    \n",
    "    self.image_is_red = {}\n",
    "    for line in self.get_text_file('custom-data.txt').splitlines():\n",
    "      (name, redness) = line.split(',')\n",
    "      self.image_is_red[name] = (redness == 'red')\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \"\"\"Return the image and the binary label\"\"\"\n",
    "    filename = self.samples[index]\n",
    "    image = self.get_image(filename)\n",
    "    is_red = self.image_is_red[filename]\n",
    "    return (image, is_red)\n",
    "\n",
    "\n",
    "dataset = RedDataset('example-data/colors.tar')\n",
    "\n",
    "for (idx, (image, label)) in enumerate(dataset):\n",
    "  print(f\"Image #{idx}, redness: {label}, color: {image[:,0,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3492b4d",
   "metadata": {},
   "source": [
    "That's it! For more information, refer to the documentation of the classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
